{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import json\n",
    "import html\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from functools import partial\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils \n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import dataset, dataloader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import data\n",
    "\n",
    "snli_root = './data/SNLI/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget https://github.com/briandw/SiameseULMFiT/releases/download/1/data.zip\n",
    "#! unzip ./data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139636\n"
     ]
    }
   ],
   "source": [
    "# load and process the all the sentences, just to get the LM trained\n",
    "raw_text = []\n",
    "for file in [f\"{snli_root}/snli_train.json\", f\"{snli_root}/snli_dev.json\", f\"{snli_root}/snli_test.json\"]:\n",
    "    with open(file) as fp:\n",
    "        content = json.load(fp)\n",
    "        for item in content:\n",
    "            raw_text.append(item[0])\n",
    "            raw_text.append(item[1])\n",
    "print(len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the language model data into train and validation sets\n",
    "lm_train, lm_valid = sklearn.model_selection.train_test_split(raw_text, test_size=0.1)\n",
    "df_trn = pd.DataFrame(lm_train)\n",
    "df_val = pd.DataFrame(lm_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'x_bos'  # beginning-of-sentence tag\n",
    "\n",
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "\n",
    "def get_texts(df):\n",
    "    texts = df[0].astype(str)\n",
    "    texts = list(texts.apply(fixup).values)\n",
    "    texts = f'{BOS} ' + df[0].astype(str)\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    return tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.concatenate(get_texts(df_trn))\n",
    "tok_val = np.concatenate(get_texts(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x_bos', 'a', 'woman', 'in', 'a', 'red', 'coat', 'is', 'leaving', 'a', 'photo', 'shop', '.', 'x_bos',\n",
       "       'a', 'young', 'redheaded', 'woman', 'laughs', 'at', 'something', '.', 'x_bos', 'a', 'man', 'comes',\n",
       "       'out', 'of', 'the', 'gene', 'pool', 'after', 'swimming', '.', 'x_bos', 'the', 'women', 'are', 'in',\n",
       "       'a', 'play', '.', 'x_bos', 'seven', 'men', 'in', 'orange', 'work', 'at', 'night', 'on', 'a',\n",
       "       'railway', ',', 'next', 'to', 'a', 'train', '.', 'x_bos', 'a', 'boy', 'is', 'playing', 'in', 'the',\n",
       "       'sand', '.', 'x_bos', 'people', 'are', 'walking', 'outside', '.', 'x_bos', 'a', 'man', 'is', 'seated',\n",
       "       'in', 'front', 'of', 'a', 'big', 'calvin', 'klein', 'ad', '.', 'x_bos', 'people', 'wearing', 'white',\n",
       "       'helmets', ',', 'looking', 'into', 'a', 'crowded', 'street', 'corner'], dtype='<U24')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_val[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save our work\n",
    "np.save(f'{snli_root}tok_trn.npy', tok_trn)\n",
    "np.save(f'{snli_root}tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(f'{snli_root}tok_trn.npy')\n",
    "tok_val = np.load(f'{snli_root}tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1495314),\n",
       " ('x_bos', 1139636),\n",
       " ('.', 999009),\n",
       " ('the', 554918),\n",
       " ('in', 423676),\n",
       " ('is', 387678),\n",
       " ('man', 276610),\n",
       " ('on', 245026),\n",
       " ('and', 215080),\n",
       " ('are', 206697),\n",
       " ('of', 200366),\n",
       " ('with', 176065),\n",
       " ('woman', 143029),\n",
       " ('two', 126872),\n",
       " ('people', 125577),\n",
       " (',', 119825),\n",
       " ('to', 118657),\n",
       " ('at', 102392),\n",
       " ('wearing', 84371),\n",
       " ('an', 83393),\n",
       " ('his', 75518),\n",
       " ('shirt', 65434),\n",
       " ('young', 64082),\n",
       " ('men', 63368),\n",
       " ('playing', 61542)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(np.concatenate([tok_trn, tok_val]))\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34153"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 1\n",
    "itos = [o for o, c in freq.most_common(max_vocab) if c>=min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')\n",
    "stoi = defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34155"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.array([stoi[p] for p in tok_trn])\n",
    "val_lm = np.array([stoi[p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "pickle.dump(itos, open(f'{snli_root}itos.pkl', 'wb'))\n",
    "np.save(f'{snli_root}trn_lm.npy', trn_lm)\n",
    "np.save(f'{snli_root}val_lm.npy', val_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34155"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the results so we can pick it up from here \n",
    "itos = pickle.load(open(f'{snli_root}itos.pkl', 'rb'))\n",
    "trn_lm = np.load(f'{snli_root}trn_lm.npy')\n",
    "val_lm = np.load(f'{snli_root}val_lm.npy')\n",
    "\n",
    "stoi = defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "vocab_size = len(itos)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_bos a woman in a red coat is leaving a photo shop . x_bos a young redheaded woman laughs at something . x_bos a man comes out of the gene pool after swimming . x_bos the women are in a play . x_bos seven men in orange work at night on a railway , next to a train . x_bos a boy is playing in the sand . x_bos people are walking outside . x_bos a man is seated in front of a big calvin klein ad . x_bos people wearing white helmets , looking into a crowded street corner "
     ]
    }
   ],
   "source": [
    "for word in val_lm[:100]:\n",
    "    print(itos[word], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
