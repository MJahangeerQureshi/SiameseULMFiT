{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import json\n",
    "import html\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from functools import partial\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils \n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import dataset, dataloader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import data\n",
    "\n",
    "snli_root = './data/SNLI/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39332\n"
     ]
    }
   ],
   "source": [
    "# load and process the all the sentences, just to get the LM trained\n",
    "raw_text = []\n",
    "for file in [f\"{snli_root}/snli_dev.json\", f\"{snli_root}/snli_test.json\"]:\n",
    "    with open(file) as fp:\n",
    "        content = json.load(fp)\n",
    "        for item in content:\n",
    "            raw_text.append(item[0])\n",
    "            raw_text.append(item[1])\n",
    "print(len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the language model data into train and validation sets\n",
    "lm_train, lm_valid = sklearn.model_selection.train_test_split(raw_text, test_size=0.1)\n",
    "df_trn = pd.DataFrame(lm_train)\n",
    "df_val = pd.DataFrame(lm_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'x_bos'  # beginning-of-sentence tag\n",
    "\n",
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "\n",
    "def get_texts(df):\n",
    "    texts = df[0].astype(str)\n",
    "    texts = list(texts.apply(fixup).values)\n",
    "    texts = f'{BOS} ' + df[0].astype(str)\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    return tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.concatenate(get_texts(df_trn))\n",
    "tok_val = np.concatenate(get_texts(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x_bos', 'a', 'man', 'with', 'an', 'orange', 'jacket', ',', 'takes', 'the', 'photo', 'of', 'four',\n",
       "       'women', ',', 'and', 'a', 'man', 'in', 'a', 'greenish', 'yellow', 'suite', '.', 'x_bos', 'a', 'young',\n",
       "       'man', 'attempts', 'to', 'pole', 'vault', 'over', 'a', 'bar', ',', 'barely', 'inches', 'away', 'from',\n",
       "       'it', 'mid', 'flight', '.', 'x_bos', 'one', 'woman', 'really', 'sucks', 'at', 'playing', 'ping',\n",
       "       'pong', '.', 'x_bos', 'in', 'a', 'little', 'league', 'baseball', 'game', ',', 'the', 'batter',\n",
       "       'watches', 'as', 'the', 'ball', 'he', 'has', 'just', 'hit', 'flies', 'off', 'toward', 'right',\n",
       "       'field', ',', 'with', 'the', 'catcher', 'looking', 'on', '.', 'x_bos', 'two', 'women', 'are', 'in',\n",
       "       'a', 'car', 'with', 'a', 'man', '.', 'x_bos', 'the', 'ball', 'is', 'on'], dtype='<U14')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_val[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save our work\n",
    "np.save(f'{snli_root}tok_trn.npy', tok_trn)\n",
    "np.save(f'{snli_root}tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(f'{snli_root}tok_trn.npy')\n",
    "tok_val = np.load(f'{snli_root}tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 54168),\n",
       " ('x_bos', 39332),\n",
       " ('.', 34564),\n",
       " ('the', 19411),\n",
       " ('in', 15767),\n",
       " ('is', 13604),\n",
       " ('man', 9985),\n",
       " ('on', 8761),\n",
       " ('and', 8388),\n",
       " ('of', 7605),\n",
       " ('are', 7312),\n",
       " ('with', 6549),\n",
       " (',', 5304),\n",
       " ('woman', 5225),\n",
       " ('to', 4493),\n",
       " ('two', 4440),\n",
       " ('people', 4242),\n",
       " ('at', 3603),\n",
       " ('wearing', 3212),\n",
       " ('an', 3059),\n",
       " ('his', 2943),\n",
       " ('shirt', 2606),\n",
       " ('young', 2483),\n",
       " ('while', 2405),\n",
       " ('men', 2287)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(np.concatenate([tok_trn, tok_val]))\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8840"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 1\n",
    "itos = [o for o, c in freq.most_common(max_vocab) if c>=min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')\n",
    "stoi = defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8842"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.array([stoi[p] for p in tok_trn])\n",
    "val_lm = np.array([stoi[p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "pickle.dump(itos, open(f'{snli_root}itos.pkl', 'wb'))\n",
    "np.save(f'{snli_root}trn_lm.npy', trn_lm)\n",
    "np.save(f'{snli_root}val_lm.npy', val_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8842"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the results so we can pick it up from here \n",
    "itos = pickle.load(open(f'{snli_root}itos.pkl', 'rb'))\n",
    "trn_lm = np.load(f'{snli_root}trn_lm.npy')\n",
    "val_lm = np.load(f'{snli_root}val_lm.npy')\n",
    "\n",
    "stoi = defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "vocab_size = len(itos)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_bos a man with an orange jacket , takes the photo of four women , and a man in a greenish yellow suite . x_bos a young man attempts to pole vault over a bar , barely inches away from it mid flight . x_bos one woman really sucks at playing ping pong . x_bos in a little league baseball game , the batter watches as the ball he has just hit flies off toward right field , with the catcher looking on . x_bos two women are in a car with a man . x_bos the ball is on "
     ]
    }
   ],
   "source": [
    "for word in val_lm[:100]:\n",
    "    print(itos[word], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
